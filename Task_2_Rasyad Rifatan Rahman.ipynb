{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>**Machine Learning Technologies</ins> - Task 2**: Natural Language Processing\n",
    "__ITMO University__, St. Petersburg, Russia\n",
    "- Name    : Rahman, Rasyad Rifatan <br>\n",
    "- ID      : 458029\n",
    "\n",
    "---\n",
    "\n",
    "1. Download Alice in Wonderland by Lewis Carroll from Project Gutenberg's website http://www.gutenberg.org/files/11/11-0.txt\n",
    "2. Perform any necessary preprocessing on the text, including converting to lower case, removing stop words, numbers / non-alphabetic characters, lemmatization.\n",
    "3. Find Top 10 most important (for example, in terms of TF-IDF metric) words from each chapter in the text (not \"Alice\"); how would you name each chapter according to the identified tokens?\n",
    "4. Find the Top 10 most used verbs in sentences with Alice. What does Alice do most often?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rasyad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rasyad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Rasyad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Rasyad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Rasyad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Access the text file through the internet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "alice = response.text\n",
    "alice = alice.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*or locally*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alice.txt\",'r',encoding='utf-8') as file:\n",
    "    alice = file.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform any necessary preprocessing on the text, including converting to lower case, removing stop words, numbers / non-alphabetic characters, lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿*** start of the project gutenberg ebook alic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chapter i.     down the rabbit-hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chapter ii.    the pool of tears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  ﻿*** start of the project gutenberg ebook alic...\n",
       "1                chapter i.     down the rabbit-hole\n",
       "2                                                   \n",
       "3                   chapter ii.    the pool of tears\n",
       "4                                                   "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice = re.split(r'(chapter\\s+[ivxlcdm]+\\.\\s+[^\\n]*)\\s*\\n', alice)\n",
    "title = alice[1::2]\n",
    "content = alice[2::2]\n",
    "\n",
    "temp_df = pd.DataFrame(alice)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chapter i.     down the rabbit-hole</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chapter ii.    the pool of tears</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chapter iii.   a caucus-race and a long tale</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chapter iv.    the rabbit sends in a little bill</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chapter v.     advice from a caterpillar</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title content\n",
       "0               chapter i.     down the rabbit-hole        \n",
       "1                  chapter ii.    the pool of tears        \n",
       "2      chapter iii.   a caucus-race and a long tale        \n",
       "3  chapter iv.    the rabbit sends in a little bill        \n",
       "4          chapter v.     advice from a caterpillar        "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'title':title,'content':content})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chapter i.\\ndown the rabbit-hole</td>\n",
       "      <td>alice was beginning to get very tired of sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chapter ii.\\nthe pool of tears</td>\n",
       "      <td>“curiouser and curiouser!” cried alice (she wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chapter iii.\\na caucus-race and a long tale</td>\n",
       "      <td>they were indeed a queer-looking party that as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chapter iv.\\nthe rabbit sends in a little bill</td>\n",
       "      <td>it was the white rabbit, trotting slowly back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chapter v.\\nadvice from a caterpillar</td>\n",
       "      <td>the caterpillar and alice looked at each other...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                chapter i.\\ndown the rabbit-hole   \n",
       "1                  chapter ii.\\nthe pool of tears   \n",
       "2     chapter iii.\\na caucus-race and a long tale   \n",
       "3  chapter iv.\\nthe rabbit sends in a little bill   \n",
       "4           chapter v.\\nadvice from a caterpillar   \n",
       "\n",
       "                                             content  \n",
       "0  alice was beginning to get very tired of sitti...  \n",
       "1  “curiouser and curiouser!” cried alice (she wa...  \n",
       "2  they were indeed a queer-looking party that as...  \n",
       "3  it was the white rabbit, trotting slowly back ...  \n",
       "4  the caterpillar and alice looked at each other...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.index[0:12])\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  \\\n",
      "0  alice was beginning to get very tired of sitti...   \n",
      "1  “curiouser and curiouser!” cried alice (she wa...   \n",
      "2  they were indeed a queer-looking party that as...   \n",
      "3  it was the white rabbit, trotting slowly back ...   \n",
      "4  the caterpillar and alice looked at each other...   \n",
      "\n",
      "                                           processed  \n",
      "0  alice beginning get tired sitting sister bank ...  \n",
      "1  curiouser curiouser cried alice much surprised...  \n",
      "2  indeed queerlooking party assembled bankthe bi...  \n",
      "3  white rabbit trotting slowly back looking anxi...  \n",
      "4  caterpillar alice looked time silence last cat...  \n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    # Remove numbers and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['processed'] = df['content'].apply(preprocess)\n",
    "print(df[['content', 'processed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Top 10 most important (for example, in terms of TF-IDF metric) words from each chapter in the text (not \"Alice\"); how would you name each chapter according to the identified tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed\"] = df[\"processed\"].apply(lambda x: re.sub(r'\\balice\\b', '', x))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"processed\"])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [little, bat, door, key, eat, way, like, think...\n",
       "1     [mouse, little, pool, im, swam, cat, dear, sai...\n",
       "2     [mouse, said, dodo, prize, lory, dry, thimble,...\n",
       "3     [window, little, bill, puppy, rabbit, glove, f...\n",
       "4     [caterpillar, said, serpent, pigeon, im, youth...\n",
       "5     [said, cat, footman, baby, mad, duchess, pig, ...\n",
       "6     [hatter, dormouse, said, hare, march, twinkle,...\n",
       "7     [queen, said, hedgehog, king, gardener, soldie...\n",
       "8     [said, turtle, mock, gryphon, duchess, moral, ...\n",
       "9     [turtle, mock, gryphon, said, dance, lobster, ...\n",
       "10    [king, hatter, said, court, dormouse, witness,...\n",
       "11    [said, king, jury, queen, sister, dream, would...\n",
       "Name: top10, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = []\n",
    "\n",
    "for i, chapter in enumerate(df['processed']):\n",
    "    tfidf_scores = tfidf_matrix[i].toarray().flatten()\n",
    "    top_indices = tfidf_scores.argsort()[-10:][::-1]\n",
    "    top_words = [vectorizer.get_feature_names_out()[j] for j in top_indices]\n",
    "    top10.append(top_words)\n",
    "\n",
    "df['top10'] = top10\n",
    "df['top10'].head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through Data Wrangler, we are able to see the full list of the top 10 words of each chapter.\n",
    "\n",
    "![top10](top10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, here's my list of what I would name each chapter based on the top 10 words:\n",
    "- **Chapter 1**     : Either Way, I Think You’ll Like It\n",
    "- **Chapter 2**     : Dear Little Mouse\n",
    "- **Chapter 3**     : The Bird Knows the Prize\n",
    "- **Chapter 4**     : The Little One by the Window\n",
    "- **Chapter 5**     : The Father of Youth\n",
    "- **Chapter 6**     : The Mad Baby\n",
    "- **Chapter 7**     : The Marching of Time\n",
    "- **Chapter 8**     : The King's Executioner\n",
    "- **Chapter 9**     : Mockery of the Duchess\n",
    "- **Chapter 10**    : Dance, o' Beautiful\n",
    "- **Chapter 11**    : The Witness' Court\n",
    "- **Chapter 12**    : Dreams of a Rabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the Top 10 most used verbs in sentences with Alice. What does Alice do most often?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alice.txt\",'r',encoding='utf-8') as file:\n",
    "    alice = file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_alice = [sentence for sentence in re.split(r'(?<=[.!?])\\s+', alice) if 'alice' in sentence]\n",
    "sentences_with_alice = [word_tokenize(sentence) for sentence in sentences_with_alice]\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "sentences_with_alice = [remove_stopwords(sentence) for sentence in sentences_with_alice]\n",
    "\n",
    "def lemmatize_words(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "sentences_with_alice = [lemmatize_words(sentence) for sentence in sentences_with_alice]\n",
    "\n",
    "sentences_with_alice = [' '.join(words) for words in sentences_with_alice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_verbs = []\n",
    "for sentence in sentences_with_alice:\n",
    "    words = word_tokenize(sentence)\n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    verbs = [word.lower() for word, tag in pos_tags if tag.startswith('V') and word.isalpha()]\n",
    "    all_verbs.extend(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Mentioned Verbs with Alice\n",
      "say: 294\n",
      "go: 85\n",
      "think: 58\n",
      "get: 47\n",
      "know: 46\n",
      "make: 36\n",
      "see: 31\n",
      "take: 31\n",
      "find: 28\n",
      "come: 25\n"
     ]
    }
   ],
   "source": [
    "verb_counts = Counter(all_verbs).most_common(10)\n",
    "\n",
    "print(\"10 Most Mentioned Verbs with Alice\")\n",
    "for verb, freq in verb_counts:\n",
    "    print(f\"{verb}: {freq}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
